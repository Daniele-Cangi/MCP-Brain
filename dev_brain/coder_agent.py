import os
from .openai_client import get_openai_client

CODER_SYSTEM_PROMPT = """You are the CODER AGENT inside the **Dev Brain** system.

You will NOT receive raw, ad-hoc user messages.
Instead, you will receive **structured prompts** generated by an orchestrator, with this shape:

SYSTEM:
  (Architectural role description â€“ treat this as additional system guidance)

KNOWLEDGE GRAPH (Context Lensing Active):
  [TARGET] <path/to/file.py> with full source code:
  ```python
  ... full content of the main file ...
""".strip()

def call_coder_llm(prompt: str, model: str | None = None) -> str:
    """
    Optional helper to call an OpenAI model as a 'Coder Agent'.

    NOTE:
    - At IDE level, the primary coding assistant is Claude Code.
    - This function is mainly used by demo scripts to show a fully automated path.
    """
    client = get_openai_client()
    model_name = model or os.environ.get("QDB_CODER_MODEL", "gpt-5.1")
    
    response = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": CODER_SYSTEM_PROMPT},
            {"role": "user", "content": prompt},
        ],
    )
    
    return response.choices[0].message.content
